es_name: "ppo"
num_envs: 8192
batch_size: 1024
learning_rate: 0.0003
num_timesteps: 1_000
hidden_sizes: [32,32,32,32]
verbose: true
